# LinkedIn Content Calendar

## 2026-02-20 — Source: Mark Atwood article (Amazon succession / innovation)

### Article summary (concise)
1. **Founder vs executor mismatch**: companies can preserve innovation rituals while losing true innovation behavior.
2. **Management-layer drift**: external management growth can filter out technical dissent.
3. **Pipeline collapse**: speculative projects often die through prioritization mechanics, not explicit rejection.
4. **Layoff effect on risk appetite**: when failure carries personal downside, people optimize for safe bets.
5. **Founder bandwidth** matters during transition windows; attention allocation shapes strategic outcomes.
6. **Risk-calibration argument**: operator skill and founder-style platform vision are different capabilities.
7. **Missed platform thesis**: claims Amazon could have built drone traffic infrastructure as a platform play.
8. **General pattern claim**: succession often preserves operations while weakening category creation.

### Publishing ideation (mapped to strategy pillars)

#### Pillar 1 — Architecture & Evaluation at Scale
- Innovation failure is usually a **system design/incentive** failure before it is a capability failure.
- Suggested angle: "In AI platforms, architecture includes incentive architecture."

#### Pillar 2 — Organizational Design & Governance
- Governance mechanisms can unintentionally suppress exploration when optimized only for predictability.
- Suggested angle: "When governance artifacts survive but dissent pathways die."

#### Pillar 3 — Enterprise Reality vs Hype
- Public discourse focuses on model choice; real failures happen in prioritization, risk policy, and operating incentives.
- Suggested angle: "Most AI failures are portfolio/process failures in disguise."

#### Pillar 4 — Decision Frameworks
- Exploration vs optimization should be a measurable portfolio choice, not implicit culture talk.
- Suggested angle: "AI org health test = exploration capacity, not post count or demo count."

### Reusable post angles from this source
1. **Ritual vs Function**
   - Claim: Documentation maturity ≠ innovation capacity.
   - Ops detail: identify where eval/review rituals exist but corrective action velocity is low.

2. **Implicit Contract Design**
   - Claim: Teams only take high-upside bets when downside is bounded.
   - Ops detail: define risk budgets and failure absorption paths.

3. **Prioritization as Kill-Switch**
   - Claim: Breakthrough ideas often die in planning filters.
   - Ops detail: add an uncertainty-adjusted strategic value lane.

4. **Efficiency vs Option Value**
   - Claim: Near-term efficiency can destroy long-term AI option value.
   - Ops detail: run a two-speed portfolio (exploit vs explore).

5. **From Founder Myth to Operating Model**
   - Claim: Exploration must be institutionalized, not personality-dependent.
   - Ops detail: formal dissent pathways + exception funding.

### Ready-to-develop posts (next 2)

#### Post A — Org design
**Working title:** Why AI innovation dies even when governance looks mature
- Hook: "Your AI principles may be alive; your exploration engine may already be dead."
- Reality gap: docs/compliance pass ≠ permission to take risk
- Operational details: failure absorption, dissent path, exception funding
- Closing principle: "Governance that cannot preserve variance is optimization theater."

#### Post B — Decision framework
**Working title:** AI portfolio health test: exploration capacity
- Hook: "Count how many weird projects survived prioritization this quarter."
- Reality gap: throughput metrics hide option destruction
- Operational details: % speculative bets, failure recovery time, promotions after failed bets
- Closing principle: "No protected downside, no real experimentation."

### Framing guardrail
- Use this source as a mechanism lens, not as personality-level attack content.
- Phrase as: "This argument highlights a mechanism worth testing in enterprise AI orgs..."
- Avoid presenting unverified personal claims as settled fact.

## Idea capture — 2026-02-23
- Post deconstructions of production failures.
- Write about RAG failure modes.
- Publish architecture tradeoffs.
- Explain institutional AI deployment constraints.
